#!/usr/bin/env python3
"""
æ•°æ®åº“è¿ç§»ç®¡ç†å·¥å…·
æ•´åˆäº†æ£€æŸ¥ã€ä¿®å¤å’Œç»´æŠ¤æ•°æ®åº“è¿ç§»çš„æ‰€æœ‰åŠŸèƒ½
"""

import os
import re
import sys
import sqlite3
import argparse
import shutil
from datetime import datetime
from pathlib import Path
from collections import defaultdict
from typing import Dict, Set, Tuple, Optional, List, Union


class MigrationManager:
    """è¿ç§»ç®¡ç†å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.migrations_dir = self.project_root / "open_webui" / "migrations" / "versions"
        self.db_path = self.project_root / "data" / "webui.db"
        self.backup_dir = self.project_root / "data" / "migration_backups"
        
    def setup(self):
        """åˆå§‹åŒ–è®¾ç½®"""
        os.chdir(self.project_root)
        if not self.migrations_dir.exists():
            print("âŒ è¿ç§»ç›®å½•ä¸å­˜åœ¨")
            return False
        return True
    
    # ========== æ£€æŸ¥åŠŸèƒ½ ==========
    
    def check_duplicate_tables(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤åˆ›å»ºè¡¨çš„è¿ç§»"""
        table_migrations = defaultdict(list)
        
        for migration_file in self.migrations_dir.glob("*.py"):
            if migration_file.name.startswith("__"):
                continue
                
            with open(migration_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æŸ¥æ‰¾ create_table è°ƒç”¨
            create_table_matches = re.findall(r'create_table\([\'"]([^\'"]+)[\'"]', content)
            for table_name in create_table_matches:
                table_migrations[table_name].append(migration_file.name)
        
        # æ£€æŸ¥é‡å¤
        duplicates = {table: files for table, files in table_migrations.items() if len(files) > 1}
        
        if duplicates:
            print("âŒ å‘ç°é‡å¤çš„è¡¨åˆ›å»º:")
            for table, files in duplicates.items():
                print(f"  è¡¨ '{table}' åœ¨ä»¥ä¸‹æ–‡ä»¶ä¸­è¢«åˆ›å»º:")
                for file in files:
                    print(f"    - {file}")
            return False
        else:
            print("âœ… æ²¡æœ‰å‘ç°é‡å¤çš„è¡¨åˆ›å»º")
            return True
    
    def check_migration_chain(self) -> bool:
        """æ£€æŸ¥è¿ç§»é“¾æ˜¯å¦è¿ç»­"""
        migrations = self._load_migrations()
        
        # æ£€æŸ¥è¿ç§»é“¾
        heads = []
        for revision, info in migrations.items():
            if info['down_revision'] is None:
                heads.append(revision)
            elif isinstance(info['down_revision'], tuple):
                # å¤„ç†åˆå¹¶è¿ç§»
                for down_rev in info['down_revision']:
                    if down_rev not in migrations:
                        print(f"âŒ è¿ç§» {revision} ({info['file']}) çš„ down_revision {down_rev} ä¸å­˜åœ¨")
                        return False
            elif info['down_revision'] not in migrations:
                print(f"âŒ è¿ç§» {revision} ({info['file']}) çš„ down_revision {info['down_revision']} ä¸å­˜åœ¨")
                return False
        
        if len(heads) > 1:
            print(f"âŒ å‘ç°å¤šä¸ªå¤´èŠ‚ç‚¹: {heads}")
            return False
        elif len(heads) == 0:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¤´èŠ‚ç‚¹")
            return False
        else:
            print(f"âœ… è¿ç§»é“¾æ­£å¸¸ï¼Œå¤´èŠ‚ç‚¹: {heads[0]}")
            return True
    
    def check_custom_revision_ids(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰çš„revision ID"""
        custom_revisions = []
        
        for migration_file in self.migrations_dir.glob("*.py"):
            if migration_file.name.startswith("__"):
                continue
                
            with open(migration_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰çš„revision IDï¼ˆä¸æ˜¯æ ‡å‡†çš„12ä½åå…­è¿›åˆ¶ï¼‰
            revision_match = re.search(r'revision\s*[:=]\s*[\'"]([^\'"]+)[\'"]', content)
            if revision_match:
                revision = revision_match.group(1)
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†çš„Alembic revision IDæ ¼å¼ï¼ˆ12ä½åå…­è¿›åˆ¶ï¼‰
                if not re.match(r'^[a-f0-9]{12}$', revision):
                    custom_revisions.append((migration_file.name, revision))
        
        if custom_revisions:
            print("âŒ å‘ç°è‡ªå®šä¹‰çš„revision ID:")
            for file, revision in custom_revisions:
                print(f"  {file}: {revision}")
            return False
        else:
            print("âœ… æ‰€æœ‰è¿ç§»éƒ½ä½¿ç”¨æ ‡å‡†çš„revision ID")
            return True
    
    def check_all(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹æ£€æŸ¥æ•°æ®åº“è¿ç§»...")
        print("=" * 50)
        
        if not self.setup():
            return False
        
        checks = [
            ("é‡å¤è¡¨æ£€æŸ¥", self.check_duplicate_tables),
            ("è¿ç§»é“¾æ£€æŸ¥", self.check_migration_chain),
            ("Revision IDæ£€æŸ¥", self.check_custom_revision_ids),
        ]
        
        all_passed = True
        for check_name, check_func in checks:
            print(f"\nğŸ“‹ {check_name}:")
            try:
                if not check_func():
                    all_passed = False
            except Exception as e:
                print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
                all_passed = False
        
        print("\n" + "=" * 50)
        if all_passed:
            print("âœ… æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡äº†ï¼")
            return True
        else:
            print("âŒ å‘ç°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ä¿®å¤åé‡æ–°æ£€æŸ¥")
            return False
    
    # ========== ä¿®å¤åŠŸèƒ½ ==========
    
    def _load_migrations(self) -> Dict:
        """åŠ è½½æ‰€æœ‰è¿ç§»æ–‡ä»¶ä¿¡æ¯"""
        migrations = {}
        
        for migration_file in self.migrations_dir.glob("*.py"):
            if migration_file.name.startswith("__"):
                continue
                
            with open(migration_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # å¢å¼ºçš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
            revision = self._extract_revision(content)
            down_revision = self._extract_down_revision(content)
            
            if revision:
                migrations[revision] = {
                    'file': migration_file.name,
                    'down_revision': down_revision,
                    'content': content
                }
        
        return migrations
    
    def _extract_revision(self, content: str) -> Optional[str]:
        """æå– revision IDï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        patterns = [
            r'revision\s*[:=]\s*[\'"]([^\'"]+)[\'"]',  # åŸºç¡€æ ¼å¼
            r'revision\s*:\s*str\s*=\s*[\'"]([^\'"]+)[\'"]',  # ç±»å‹æ³¨è§£
            r'revision\s*:\s*Optional\[str\]\s*=\s*[\'"]([^\'"]+)[\'"]',  # Optionalç±»å‹
            r'revision\s*=\s*[\'"]([^\'"]+)[\'"]',  # ç®€å•èµ‹å€¼
            # å¤šè¡Œæ ¼å¼
            r'revision\s*[:=]\s*\(\s*[\'"]([^\'"]+)[\'"]\s*\)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
            if match:
                return match.group(1)
        return None
    
    def _extract_down_revision(self, content: str) -> Optional[Union[str, tuple]]:
        """æå– down_revisionï¼Œæ”¯æŒå¤šç§æ ¼å¼"""
        # æ£€æŸ¥ None å€¼
        if re.search(r'down_revision\s*[:=]\s*None', content):
            return None
            
        patterns = [
            # å•ä¸ªå­—ç¬¦ä¸²
            r'down_revision\s*[:=]\s*[\'"]([^\'"]+)[\'"]',
            r'down_revision\s*:\s*Union\[str,\s*None\]\s*=\s*[\'"]([^\'"]+)[\'"]',
            r'down_revision\s*:\s*Optional\[str\]\s*=\s*[\'"]([^\'"]+)[\'"]',
            # å…ƒç»„æ ¼å¼ (åˆå¹¶è¿ç§»)
            r'down_revision\s*[:=]\s*\(\s*[\'"]([^\'"]+)[\'"]\s*,\s*[\'"]([^\'"]+)[\'"]\s*\)',
            r'down_revision\s*:\s*Union\[str,\s*tuple\[str,\s*str\],\s*None\]\s*=\s*\(\s*[\'"]([^\'"]+)[\'"]\s*,\s*[\'"]([^\'"]+)[\'"]\s*\)',
            r'down_revision\s*:\s*Tuple\[str,\s*str\]\s*=\s*\(\s*[\'"]([^\'"]+)[\'"]\s*,\s*[\'"]([^\'"]+)[\'"]\s*\)',
            # å¤šè¡Œå…ƒç»„æ ¼å¼
            r'down_revision\s*[:=]\s*\(\s*[\'"]([^\'"]+)[\'"]\s*,\s*[\'"]([^\'"]+)[\'"]\s*\)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
            if match:
                groups = match.groups()
                if len(groups) == 1:
                    return groups[0]
                elif len(groups) == 2:
                    return (groups[0], groups[1])
        
        return None
    
    def _find_valid_head(self, migrations: Dict) -> Optional[str]:
        """æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„å¤´èŠ‚ç‚¹"""
        # æ‰¾åˆ°æ‰€æœ‰æ²¡æœ‰è¢«å…¶ä»–è¿ç§»æŒ‡å‘çš„revision
        all_down_revisions = set()
        for info in migrations.values():
            if info['down_revision']:
                if isinstance(info['down_revision'], tuple):
                    all_down_revisions.update(info['down_revision'])
                else:
                    all_down_revisions.add(info['down_revision'])
        
        heads = [rev for rev in migrations.keys() if rev not in all_down_revisions]
        
        if len(heads) == 1:
            return heads[0]
        elif len(heads) > 1:
            print(f"âš ï¸  å‘ç°å¤šä¸ªå¤´èŠ‚ç‚¹: {heads}")
            # é€‰æ‹©æœ€æ–°çš„ä¸€ä¸ªï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰
            heads.sort(key=lambda x: migrations[x]['file'])
            return heads[-1]
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¤´èŠ‚ç‚¹")
            return None
    
    def _update_database_version(self, target_revision: str) -> bool:
        """æ›´æ–°æ•°æ®åº“ç‰ˆæœ¬è®°å½•"""
        if not self.db_path.exists():
            print("âš ï¸  æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ç‰ˆæœ¬æ›´æ–°")
            return True
            
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ£€æŸ¥å½“å‰ç‰ˆæœ¬
            cursor.execute("SELECT version_num FROM alembic_version")
            current_version = cursor.fetchone()
            
            if current_version:
                print(f"å½“å‰æ•°æ®åº“ç‰ˆæœ¬: {current_version[0]}")
            
            # æ›´æ–°ç‰ˆæœ¬
            cursor.execute("UPDATE alembic_version SET version_num = ?", (target_revision,))
            conn.commit()
            
            print(f"âœ… æ•°æ®åº“ç‰ˆæœ¬å·²æ›´æ–°ä¸º: {target_revision}")
            conn.close()
            return True
            
        except Exception as e:
            print(f"âŒ æ›´æ–°æ•°æ®åº“ç‰ˆæœ¬å¤±è´¥: {e}")
            return False
    
    def fix_chain(self):
        """ä¿®å¤è¿ç§»é“¾æ–­è£‚é—®é¢˜"""
        print("ğŸ”§ è¿ç§»é“¾ä¿®å¤å·¥å…·")
        print("=" * 50)
        
        if not self.setup():
            return False
        
        # åˆ†æè¿ç§»é“¾
        print("ğŸ“‹ æ­¥éª¤1: åˆ†æè¿ç§»é“¾")
        migrations = self._load_migrations()
        
        # æ£€æŸ¥ç¼ºå¤±çš„revision
        missing_revisions = set()
        for revision, info in migrations.items():
            if info['down_revision']:
                if isinstance(info['down_revision'], tuple):
                    for down_rev in info['down_revision']:
                        if down_rev not in migrations:
                            missing_revisions.add(down_rev)
                            print(f"âŒ è¿ç§» {revision} ({info['file']}) çš„ down_revision {down_rev} ä¸å­˜åœ¨")
                elif info['down_revision'] not in migrations:
                    missing_revisions.add(info['down_revision'])
                    print(f"âŒ è¿ç§» {revision} ({info['file']}) çš„ down_revision {info['down_revision']} ä¸å­˜åœ¨")
        
        if not missing_revisions:
            print("âœ… è¿ç§»é“¾æ­£å¸¸ï¼Œæ— éœ€ä¿®å¤")
            return True
        
        # æ‰¾åˆ°æœ‰æ•ˆçš„å¤´èŠ‚ç‚¹
        print("\nğŸ“‹ æ­¥éª¤2: æ‰¾åˆ°æœ‰æ•ˆçš„å¤´èŠ‚ç‚¹")
        target_head = self._find_valid_head(migrations)
        if not target_head:
            print("âŒ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„å¤´èŠ‚ç‚¹")
            return False
        
        print(f"âœ… æ‰¾åˆ°æœ‰æ•ˆå¤´èŠ‚ç‚¹: {target_head}")
        
        # ä¿®å¤è¿ç§»é“¾
        print("\nğŸ“‹ æ­¥éª¤3: ä¿®å¤è¿ç§»é“¾")
        print(f"ğŸ”§ å¼€å§‹ä¿®å¤è¿ç§»é“¾ï¼Œç›®æ ‡å¤´èŠ‚ç‚¹: {target_head}")
        
        # æ„å»ºä»ç›®æ ‡å¤´èŠ‚ç‚¹å¼€å§‹çš„å®Œæ•´é“¾
        valid_chain = set()
        current = target_head
        
        while current and current in migrations:
            valid_chain.add(current)
            down_rev = migrations[current]['down_revision']
            if isinstance(down_rev, tuple):
                # å¯¹äºåˆå¹¶è¿ç§»ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„ä¸‹æ¸¸
                for rev in down_rev:
                    if rev in migrations:
                        current = rev
                        break
                else:
                    current = None
            else:
                current = down_rev
        
        print(f"âœ… æœ‰æ•ˆè¿ç§»é“¾åŒ…å« {len(valid_chain)} ä¸ªè¿ç§»æ–‡ä»¶")
        
        # æ‰¾å‡ºä¸åœ¨æœ‰æ•ˆé“¾ä¸­çš„è¿ç§»æ–‡ä»¶
        invalid_migrations = []
        for revision, info in migrations.items():
            if revision not in valid_chain:
                invalid_migrations.append((revision, info['file']))
        
        if invalid_migrations:
            print(f"\nâš ï¸  å‘ç° {len(invalid_migrations)} ä¸ªæ— æ•ˆçš„è¿ç§»æ–‡ä»¶:")
            for revision, filename in invalid_migrations:
                print(f"  - {filename} (revision: {revision})")
            
            # è¯¢é—®æ˜¯å¦åˆ é™¤
            response = input("\næ˜¯å¦åˆ é™¤è¿™äº›æ— æ•ˆçš„è¿ç§»æ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
            if response == 'y':
                deleted_count = 0
                for revision, filename in invalid_migrations:
                    try:
                        file_path = self.migrations_dir / filename
                        # å¤‡ä»½æ–‡ä»¶
                        if self._backup_file(file_path):
                            file_path.unlink()
                            print(f"  âœ… å·²åˆ é™¤: {filename}")
                            deleted_count += 1
                        else:
                            print(f"  âŒ å¤‡ä»½å¤±è´¥ï¼Œè·³è¿‡åˆ é™¤: {filename}")
                    except Exception as e:
                        print(f"  âŒ åˆ é™¤å¤±è´¥ {filename}: {e}")
                
                print(f"\nâœ… å…±åˆ é™¤äº† {deleted_count} ä¸ªæ— æ•ˆçš„è¿ç§»æ–‡ä»¶")
            else:
                print("âŒ ç”¨æˆ·å–æ¶ˆäº†åˆ é™¤æ“ä½œ")
                return False
        
        # æ›´æ–°æ•°æ®åº“ç‰ˆæœ¬
        print("\nğŸ“‹ æ­¥éª¤4: æ›´æ–°æ•°æ®åº“ç‰ˆæœ¬")
        self._update_database_version(target_head)
        
        print("\n" + "=" * 50)
        print("âœ… è¿ç§»é“¾ä¿®å¤å®Œæˆï¼")
        self._print_suggestions()
        return True
    
    def fix_duplicates(self):
        """åˆ é™¤é‡å¤çš„è¿ç§»æ–‡ä»¶å¹¶ä¿®å¤æ•°æ®åº“ç‰ˆæœ¬"""
        print("ğŸ”§ æ•°æ®åº“è¿ç§»ä¿®å¤å·¥å…·")
        print("=" * 50)
        
        if not self.setup():
            return False
        
        print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶: {self.db_path}")
        
        # 1. åˆ é™¤é‡å¤çš„è¿ç§»æ–‡ä»¶
        print("\nğŸ“‹ æ­¥éª¤1: åˆ é™¤é‡å¤çš„è¿ç§»æ–‡ä»¶")
        
        # æŒ‰è¡¨ååˆ†ç»„è¿ç§»æ–‡ä»¶
        table_migrations = defaultdict(list)
        
        for migration_file in self.migrations_dir.glob("*.py"):
            if migration_file.name.startswith("__"):
                continue
                
            with open(migration_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æŸ¥æ‰¾ create_table è°ƒç”¨
            create_table_matches = re.findall(r'create_table\([\'"]([^\'"]+)[\'"]', content)
            for table_name in create_table_matches:
                table_migrations[table_name].append(migration_file)
        
        # åˆ é™¤é‡å¤çš„è¿ç§»æ–‡ä»¶
        deleted_files = []
        for table, files in table_migrations.items():
            if len(files) > 1:
                print(f"å‘ç°é‡å¤åˆ›å»ºè¡¨ '{table}' çš„è¿ç§»æ–‡ä»¶:")
                for file in files:
                    print(f"  - {file.name}")
                
                # ä¿ç•™æœ€æ–°çš„æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼Œé€šå¸¸åŒ…å«æ—¶é—´æˆ³ï¼‰
                files.sort(key=lambda x: x.name)
                files_to_delete = files[:-1]  # åˆ é™¤é™¤äº†æœ€åä¸€ä¸ªä¹‹å¤–çš„æ‰€æœ‰æ–‡ä»¶
                
                for file in files_to_delete:
                    try:
                        # å¤‡ä»½æ–‡ä»¶
                        if self._backup_file(file):
                            file.unlink()
                            deleted_files.append(file.name)
                            print(f"  âœ… å·²åˆ é™¤: {file.name}")
                        else:
                            print(f"  âŒ å¤‡ä»½å¤±è´¥ï¼Œè·³è¿‡åˆ é™¤: {file.name}")
                    except Exception as e:
                        print(f"  âŒ åˆ é™¤å¤±è´¥ {file.name}: {e}")
        
        if deleted_files:
            print(f"\nâœ… å…±åˆ é™¤äº† {len(deleted_files)} ä¸ªé‡å¤çš„è¿ç§»æ–‡ä»¶")
        else:
            print("âœ… æ²¡æœ‰å‘ç°é‡å¤çš„è¿ç§»æ–‡ä»¶")
        
        # 2. æ‰¾åˆ°æœ€æ–°çš„è¿ç§»ç‰ˆæœ¬
        print("\nğŸ“‹ æ­¥éª¤2: æ‰¾åˆ°æœ€æ–°çš„è¿ç§»ç‰ˆæœ¬")
        migrations = self._load_migrations()
        latest_revision = self._find_valid_head(migrations)
        
        if not latest_revision:
            print("âŒ æ— æ³•æ‰¾åˆ°æœ€æ–°çš„è¿ç§»ç‰ˆæœ¬")
            return False
        
        print(f"âœ… æœ€æ–°è¿ç§»ç‰ˆæœ¬: {latest_revision}")
        
        # 3. ä¿®å¤æ•°æ®åº“ç‰ˆæœ¬
        print("\nğŸ“‹ æ­¥éª¤3: ä¿®å¤æ•°æ®åº“ç‰ˆæœ¬")
        if not self._update_database_version(latest_revision):
            print("âŒ ä¿®å¤æ•°æ®åº“ç‰ˆæœ¬å¤±è´¥")
            return False
        
        print("\n" + "=" * 50)
        print("âœ… è¿ç§»ä¿®å¤å®Œæˆï¼")
        self._print_suggestions()
        return True
    
    def fix_all(self):
        """æ‰§è¡Œæ‰€æœ‰ä¿®å¤æ“ä½œ"""
        print("ğŸ”§ å®Œæ•´ä¿®å¤æµç¨‹")
        print("=" * 50)
        
        if not self.setup():
            return False
        
        # å…ˆæ£€æŸ¥é—®é¢˜
        print("\nğŸ“‹ ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ç°æœ‰é—®é¢˜")
        self.check_all()
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­ä¿®å¤
        response = input("\næ˜¯å¦ç»§ç»­æ‰§è¡Œè‡ªåŠ¨ä¿®å¤ï¼Ÿ(y/N): ").strip().lower()
        if response != 'y':
            print("âŒ ç”¨æˆ·å–æ¶ˆäº†ä¿®å¤æ“ä½œ")
            return False
        
        # æ‰§è¡Œä¿®å¤
        print("\nğŸ“‹ ç¬¬äºŒæ­¥ï¼šåˆ é™¤é‡å¤è¿ç§»")
        self.fix_duplicates()
        
        print("\nğŸ“‹ ç¬¬ä¸‰æ­¥ï¼šä¿®å¤è¿ç§»é“¾")
        self.fix_chain()
        
        # å†æ¬¡æ£€æŸ¥
        print("\nğŸ“‹ ç¬¬å››æ­¥ï¼šéªŒè¯ä¿®å¤ç»“æœ")
        return self.check_all()
    
    def _backup_file(self, file_path: Path) -> bool:
        """å¤‡ä»½æ–‡ä»¶åˆ°å¤‡ä»½ç›®å½•"""
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"{file_path.stem}_{timestamp}{file_path.suffix}"
            backup_path = self.backup_dir / backup_filename
            
            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(file_path, backup_path)
            print(f"  ğŸ“ å·²å¤‡ä»½åˆ°: {backup_path.relative_to(self.project_root)}")
            return True
            
        except Exception as e:
            print(f"  âŒ å¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def _print_suggestions(self):
        """æ‰“å°åç»­å»ºè®®"""
        print("\nğŸ“ å»ºè®®:")
        print("1. é‡æ–°å¯åŠ¨åº”ç”¨: ./dev.sh æˆ– start_windows.bat")
        print("2. æ£€æŸ¥åº”ç”¨æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        print("3. è¿è¡Œè¿ç§»æ£€æŸ¥: python scripts/migration_manager.py check")
        if self.backup_dir.exists() and any(self.backup_dir.iterdir()):
            print(f"4. å¤‡ä»½æ–‡ä»¶ä½äº: {self.backup_dir.relative_to(self.project_root)}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ•°æ®åº“è¿ç§»ç®¡ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python scripts/migration_manager.py check          # æ£€æŸ¥è¿ç§»é—®é¢˜
  python scripts/migration_manager.py fix-chain      # ä¿®å¤è¿ç§»é“¾
  python scripts/migration_manager.py fix-duplicates # åˆ é™¤é‡å¤è¿ç§»
  python scripts/migration_manager.py fix-all        # æ‰§è¡Œæ‰€æœ‰ä¿®å¤
        """
    )
    
    parser.add_argument(
        'command',
        choices=['check', 'fix-chain', 'fix-duplicates', 'fix-all'],
        help='è¦æ‰§è¡Œçš„æ“ä½œ'
    )
    
    args = parser.parse_args()
    
    manager = MigrationManager()
    
    try:
        if args.command == 'check':
            success = manager.check_all()
        elif args.command == 'fix-chain':
            success = manager.fix_chain()
        elif args.command == 'fix-duplicates':
            success = manager.fix_duplicates()
        elif args.command == 'fix-all':
            success = manager.fix_all()
        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {args.command}")
            success = False
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
